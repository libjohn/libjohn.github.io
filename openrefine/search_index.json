[
["index.html", "Cleaning Data with OpenRefine Preface", " Cleaning Data with OpenRefine John Little 2018-05-01 Preface This lab workbook contains hands-on material supplementing the OpenRefine workshops taught by John Little and hosted by the Data &amp; Visualization Services Department, Duke University Libraries. Recent modification of this workbook were written to augment a series of slide deck presentations developed for the Data Science Visualization Institute for Librarians. The intent of the slides and workbook work together, along with face-to-face presentations, encourage data savvy skills development. Use these resources to guide your learning through a series of data experiments illustrating different aspects of data manipulation. If you’d like, watch a video recorded from an earlier workshop. Additionally, short-clip, silent videos are integrated into the workbook chapters. The soundless quality of these instructional videos are intended to enhance student learning during group learning labs by offering addition instructional options during group training sessions. The videos can also serve to illustrate concepts and techniques presented in the workbook, which otherwise has minimal explanatory text. Data and workbook are shareable under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.(CC BY-NC-SA license) "],
["preamble.html", "Preamble Workshop Philosophy On Data Cleaning Workshop Video For Best Results Comparative Advantage Characteristics Reproducible Documentation", " Preamble OpenRefine for Data Cleaning: An Outline for the Workshop John Little Data &amp; Visualization Services (the /Edge - Bostock Library) Duke University Libraries tl;dr… OpenRefne = good; data cleaning = good; learn by doing; Skip to the hands-on sections in this workbook. Testimonial I like OpenRefine for data cleaning, exploratory scripting, and data gathering including API orchestration. Refine is both very good and very easy to use. The comparative advantage lies with the ease of design and simple menu-navigation allowing the user to perform reproducible and shareable data transformations. There are other programming languages/tools (such as R, Python, Excel, or Google Sheets) which can accomplish many of the same tasks. The unique advantage for Refine may be the clustering technology. It is easy to find and correct spelling variations, or generally clean dirty and unstructured data. Indeed, for the specific task of data cleaning, OpenRefine is unquestionably easy to learn and easy to use. The power of the menu operations afford sophistication without having to memorize programming language syntax or commands. If you’re not a programmer this can be a huge value. Essentially you can remain a subject expert in your field but perform powerful transformations without feeling like you are on dual-track treadmill – trying to become a programmer and a subject expert. OpenRefine relieves me of the need to memorize file handle syntax, file management, or even looping and logic structure syntax. But all of those techniques are availble to me if and when I really want them. For programmers there is a benefit of not clouding up your wetware with a whole passel of commands which might only confound you as they muddle your expertise with another programming language. (Oh, I know this never happens to you, but it does to others – I’ve heard told). Combine ease-of-use qualities with reproducibility and it’s almost mind boggling that Refine is not more famous. The simple secret is Refine is easy to learn and offers an extensible feature set. In short, OpenRefine produces dividends for the effort you put into it. And it really grows on you. I hope you enjoy learning about OpenRefine. Workshop Philosophy I developed this workbook to consist of hands-on exercises that will reinforce my in-person instruction. My instruction is aimed at promoting a learn-by-doing, and learn-by-observation approach. So, essentially, if you’re in the workshop, you can listen to my brief introdution and then skip to the hands-on sections. Or you can watch the recording (below.) The remainder of this section consists of some overview about OpenRefine that may be important. At the same time, it’s lecture, so we may learn it another way in the workshop. I like to think of this workshop and workbook as a cooking metaphor. I’ll introducing you to a bunch of spices (functions). Then I’ll give you some recipes. I won’t give you a lot of theory. If you complete each recipe and follow each step, the recipe will turn out. If you pay attention, you learn something about how to combine the elements. Your exposure to the spices will help you learn what works and what you like. Best of all, as you gain experience with the possibilities you can learn more as you experiment on your own. On Data Cleaning It has been written that 80% of any data project is comprised of data cleaning. Furthermore, of that data cleaning part, 80% of that is tedious while the remaining 20% is confusing. I prefer to think of data cleaning as a puzzle rather than a tedium. Data cleaning is a necessary step. If given short shrift, your data will become problematic and the clearning process will still have to be addressed. Finally, since this is not an analysis book, let me remind you of the old adage: “garbage in, garbage out”. Clean your data and decrease the chances of producing garbage. Keeping in mind that the bulk of any data project involves data cleaning, you may as well have the best tools at your fingertips; you may as well do a good job; and, you may as well enjoy the puzzle. OpenRefine to the rescue… One reason data cleaning is such a challenge is that information is naturally unstructured. Meanwhile, most analysis tools prefer precise data structures. Transforming your unstructure mass into a proper structure is often as idiosyncratic as the data you are trying to analyze. Therefore, I invite you to learn about data cleaning in this workbook. Workshop Video This recording is from a previous workshop. Although some of the content has changed, you can follow the video covering the first two hands-on sections. On the DVS workshop recordings page. For Best Results The hands-on approach includes a reliance on the data-science notion of “hacking” (not “cracking”). Pay attention to what you are seeing, what you are typing, what happens, what transforms, the end-result vis-a-vis the initial state of the data. Learn by doing Learn best by working on your own project Comparative Advantage Why Use OpenRefine vs. Excel or other tools? Easy Menu driven faceting, and filtering Clean up data inconsistencies using powerful clustering and edit algorithms Transforming Data Advanced power comes from Regular Expressions implementation via GREL Web scraping: API orchestration, HTML/JSON parsing Why Use OpenRefine? you don’t want to be a data engineer, but you need to fix your data Don’t have to deal with file handling Don’t have to deal with iterating (looping logic) Don’t have to write complex conditional statements Don’t have to think hard to manipulate arrays Or, you are a lazy programmer (i.e. a smart programmer) Or, you are a subject matter expert and Refine is the right tool for the job Frequently, OpenRefine is simpler to use than Excel for data transformations Regular Expressions vs. Excel Formulas 1 Expression Language Expression GREL value.match(/(^[0-9]{1,2}\\w\\w)\\s(.*)/)[0] Excel Formula INDEX(salary!$C$1:$C$4,MATCH(1,('player DB'!$A2=salary!$A$1:$A$4)*('player DB'!$B2=salary!$B$1:$B$4),0)) Characteristics General OpenRefine is an open source data cleaning and transformation application used for Data Wrangling. Refine looks like a spreadsheet but it’s really a database There is an OpenRefine statistical extension for simple statistics Extensions are listed on the download page Transformations are performed on all MATCHING rows Easily find the “shape” of the data User Interface is your local web browser (Chrome or Firefox) Application is a Java Virtual Machine (JVM) on your local CPU – not a cloud service File ingest Formats include: TSV, CSV, Excel, XML, RDF, JSON, Google Fusion Tables and Google Spreadsheets Paste in raw data Scrape from the Web Orchestrate API calls File export Formats include: TSV, CSV, Excel, HTML table, Templating (e.g. JSON), and whole OpenRefine Projects Auto-save your projects Auto-save all processing steps Enables export and share 50,000 Rows (1.4 GB RAM ) ; Upper limit is about 5 Million Rows (requires some memory allocation) Video Watch this excellent and brief Video Introduction. It only takes a few minutes. And then watch part 2 and part 3 to expand your knowledge. Reproducible Refine supports reproducible research. Undo: every step is recorded and can be undone. Share: your steps are recorded and can be shared in a JSON notation Rerun: did I say your steps are recorded? Not only that, but those “recordings” can be shared with others or re-run on future data. Projects: each OpenRefine “project” retains a history of all your steps. The project can be exported and subsquently imported to other instances of OpenRefine. Exporting: There is a powerful export mechanism that allows you to build selective reports Documentation User documentation is the “Official Documentation Wiki” The Using OpenRefine Book, the email list, and other stuff The regex v excel-formul table is not a “fair fight” but it does illustrate what all regular expression users understand: regex is a better tool than excel formulas for data cleaning.↩ "],
["demonstration.html", "Demonstration Load Data Navigating the “Project” Facets Rows vs. Records Web Scrape &amp; API Parsing Data Split Concatenate Find &amp; Replace Facet by Blank Text filter Custom Facet", " Demonstration Load Data Create Project &gt; Web Addresses (URLs) &gt; https://raw.githubusercontent.com/libjohn/openrefine/master/data/bicycle-subset-phm-collection.tsv Uncheck - “Quotation marks are used to enclose” (bottom-right) Project Name to “bicycle categories” Navigating the “Project” Notice there are 72 rows Notice there are two views: rows and records The “records” view is for advanced manipulation You can “Show” 5-50 rows at a time Navigate screens “&lt; Previous” &amp; “next &gt;” Facets Categories &gt; Facet &gt; Text facet Notice mashup of “pipe delimited” text facets Why are there Pipe delimiters? How many Category choices exist? Switch between the “name” and “count” sorting options. Export a CSV file Export &gt; Comma-separated value How many rows will export: 4, 16, 72, 180? Rows vs. Records Row v Records 2 Categories &gt; edit cells &gt; split multi-valued cells &gt; separator = | Now how many Category choices exist? Click records to switch to the records view Click count What is the most popular Category term? Click name Limit to the “Juvenilia” facet; How many matching records? Web Scrape &amp; API Scraping data from an API or Webpage new_link &gt; Edit column &gt; Add column by fetching URLs… New column name = Web Data Notice Throttle delay 2000 milliseconds is good. Less than 2 seconds and you might get booted, blocked, cast out! Click OK and wait When done, you’ve got all the source data for each page associated with the link in the “Persistent Link” column Parsing Data A Brief Introduction Look fora big block of gobbly text in the “Web Data” column. That is HTML formatted data Typically, after fetching data, you’ll need to parse it You can use GREL 3 to parse data and isolate a specific bit of desired information GREL is the advanced power of OpenRefine. We will come back to this For example, you can transform the data in the retrieved cells with a regular expression to gather only the title of each object Web Data &gt; Edit column &gt; Add column based on this column… New Column Name = Web Page Title Expression = value.parseHtml().select(&quot;h1.object-page__title&quot;)[0].htmlText() Split remove faceting: click Remove All in the facet sidebar Production Date &gt; Edit column &gt; Split into several columns… Seperator = - (i.e. “space dash space”) Concatenate Height &gt; Edit column &gt; Add column based on this column GREL Expression = value + &quot; x &quot; + cells[&quot;Width&quot;].value Find &amp; Replace Dimension &gt; Edit cells &gt; Transform GREL Expression = value.replace(&quot;mm&quot;,&quot;&quot;) Facet by Blank Dimension &gt; Facet &gt; Customized facet &gt; facet by blank Text filter Clear all facets Title = bmx Custom Facet Production date Facet &gt; custom text facet value.match(/(\\d\\d).*/)[0] Row v Records Explained↩ General Refine Expression Language↩ "],
["start.html", "1 Hands-on: basic transformations 1.1 Getting Started 1.2 Shutting Down OpenRefine 1.3 Facets &amp; Cluster 1.4 Split data in cells 1.5 Concatenate cells together 1.6 Search &amp; Replace, Plus More 1.7 Web Scraping", " 1 Hands-on: basic transformations 1.1 Getting Started We’ll use a subset4 of Raleigh Building Permits data Launch the Open-Refine icon from your computer (find and double-click the jewel icon.) Installations / Start / Stop instructions Owen Stephens’s helpful video illustrating installation Remember: The User Interface for Refine is Chrome or Firefox If your default browser is one of these, Refine will auto-launch to http://127.0.0.1:3333 If your default browser is IE, you’ll need to open the following URL http://127.0.0.1:3333 in Chrome or Firefox Create Project &gt; Web Addresses (URLs) &gt; https://github.com/libjohn/openrefine/raw/master/data/subset%20Raleigh%20Building%20Permits.csv Click Next &gt;&gt; Select: Columns are separated by “commas (CSV)” Change the Project Name to Raleigh Building Permits and click Create Project &gt;&gt; (top-right) 1.2 Shutting Down OpenRefine It’s IMPORTANT to properly shutdown the application. OpenRefine will automatically save your project as you transform your data. However, in my experience your last operation may have to be manually saved by following the procedures below… Windows: Control-C Mac: Click the OR app in the doc, invoke Quit NOTE: It is possible, but not guaranteed, to lose data if you don’t follow the rather unintuitive shutdown procedures. Better safe than sorry. 1.3 Facets &amp; Cluster Facet &amp; Cluster Goal 1: Create a facet of authorized work. Cluster &amp; Merge types of authorized work. How many rows are in this dataset? 21,982 rows Slide the bottom column navigation bar to the right find the authorized_work column click the column header: authorized_work &gt; Facet &gt; Text facet How many facets are there? 7633 choices You may see a program warning, a dialog-box error message screen shot prompting you to set the maximum number of choices show in the text facet. If so, accept the default and proceed. In the Facet box, click count. What is the 4th most popular type of authorized work? SCREEN PORCH How many permits are recorded? 233 To find spelling clusters, click the Cluster button in the facet box Click the Select All button, then the Merge Selected &amp; Re-Cluster button, to merge all terms (accepting the default: Method = “key collision” ; Keying Function = “fingerprint”) Repeat previous step using the “ngram-fingerprint” Keying Function, then close the Cluster &amp; Edit dialog box How many SCREEN PORCH facets now exist? 238 - Compare to your answer in #4 above Compound Facets Select the DECK Facet. How many matching rows match the Deck Facet? 340 matching rows Select the SCREEN PORCH facet combined with the DECK Facet. (Hover your mouse over the facet, click include) Now how many matching rows exist? 578 matching rows On the “land_use_code” column, make a text facet and limit to “SINGLE FAMILY” On the “county” column, make a text facet and limit to Durham County (DURH) How many “Single Family” homes received permits in Durham County for Screen Porches or Decks? 3 Is the authorized work for Screen Porches, Decks, or both? both Click the “Remove All” button to remove all text facets. How many matching rows are in the dataset now? 21,982 Mass Editing It’s important to understand OpenRefine was designed to transform data in bulk. It is possible to edit single data cells but it is not as convenient as some other, more WYSWIG, tools. This exercise will help you learn how to accomplish these kinds of mass data transformations Make a Text facet on the work_type_description column There are two facets for new buildings: “NEW BUILDING” and “New Building”. How many “NEW BUILDING” rows exist? (click to reveal answer) 3 matching rows how many “New Building” rows exist? 9,668 matching rows Select “NEW BUILDING” facet, limiting to 3 matching rows. To the right of the “NEW BUILDING” facet, hover your mouse over the “edit” feature; click “edit” and alter the text to title case: “New Building” ; click Apply How many “New Building” rows exist now? 9,671 matching rows Mass edit “OTHER” &amp; “Other” so they have the same value Mass edit “ALTERATIONS/REPAIRS” and “Alterations/repairs” so they have the same value Click “Remove All” to remove the facet window 1.4 Split data in cells address &gt; Edit column &gt; Split into several columns… Separator = ( &gt; OK address 2 &gt; Edit column &gt; Split into several columns… Separator = , (i.e. accept default and click) &gt; OK address 2 1 &gt; Edit column &gt; rename this column latitude address 2 2 &gt; Edit column &gt; rename this column longitude (more data transformation could be done, but let’s move on for now…) 1.5 Concatenate cells together square_feet &gt; Edit column &gt; Add column based on this column… New column name = Full Description Expression = value + cells[&quot;proposed_work&quot;].value The last step adds two columns together, but the preview screen is hard to read. Make it readable by using the next expression instead … Expression = value + &quot; sq ft. &quot; + cells[&quot;proposed_work&quot;].value &gt; OK 1.6 Search &amp; Replace, Plus More Looking at the latitude and longitude cells, one column appears in green text (indicating OpenRefine considers data those cells as numbers) and one column appears in black with a closing parenthesis in the last position. Convert both columns to text, trim leading and trailing spaces, and then find and replace the parenthesis Convert Data Types latitude &gt; Edit cells &gt; common transformations &gt; To text Remove Whitespace longitude &gt; Edit cells &gt; common transformations &gt; Trim leading and trailing whitespace Search &amp; Replace Search and Replace is commonly performed as a data transformation using the following function: value.search(&quot;old text&quot;,&quot;new text&quot;). In the example below we replace a closing parenthesis with nothing, effectively removing the trailing parenthesis. The example may appear strange since the replace function exists within a set of parenthesis. Remember the text you are replacing is idnetified within the first set of quotation marks You will identify as the replacing text within the second set of quotation marks. I’ve draw red circles around the function, as well as the before and after text preview to clarify how the process will work. longitude &gt; Edit cells &gt; Transform… Expression = value.replace(&quot;)&quot;,&quot;&quot;) 1.7 Web Scraping Select a subset We want to gather the FIPS code for a subset of the data. The government server returns data in a JSON format so we’ll parse the data after we retrieve it. First we’ll subset our dataset for expediency. This limits our waiting time during the workshop. issue_date &gt; Facet &gt; Custom text facet… expression = value.slice(6,10) select the “2014” facet authorized_work &gt; Facet &gt; Text facet select the “3 SEASON ROOM” facet You should now have 6 matching rows. API Now let’s fetch the data from an API made available via the National Broadband Map. This API returns a FIPS code if we give it a county name (or in this case, even a partial county name.) fetch JSON data from the National Broadband Map. We’ll use the API documentation for Geography by Name API which returns Census geography for a geography name (e.g. Durham) Documentation The documentation informs us that the format of the URL we want to construct is as follows: http://www.broadbandmap.gov/broadbandmap/census/county/durh?format=json Notice the data values in the “county” column. All we do is construct a URL which calls the value of the cells from each row of the “country” column county &gt; Edit column &gt; Add column by fetching URLs… New column name = JSON data Throttle delay = 2000 Expression = 'https://www.broadbandmap.gov/broadbandmap/census/county/'+value+'?format=json' OK Wait for the results. If you limited to the matching rows in the select subset section this will only take a few seconds. Parse Now parse the value of the JSON data “fips” element; call the “fips” key when traversing the “county” objects from the Results set. JSON data &gt; Edit column &gt; Add column based on this column … New column name = FIPS Code expression = value.parseJson().Results.county[0].fips Note the square-bracket ([0]) notation in the ParseJson() function denotes and identifies the first array element. It’s the first element because in OpenRefine counting begins with zero (e.g. 0,1,2,3,4,5). The county array in the example below consists of only 1 value element (consisting of four, named key/value pairs; of which fips is one key). Since the JSON notation indicates county is an array, in this case of quantity 1, we identify that first element of the array by the number ‘0’. See the JSON example below JSON Data Example JSON 5 is JavaScript Object Notation a data wrapper. The API, in this case, returns the data in a JSON format. { \"status\": \"OK\", \"responseTime\": 14, \"message\": [ ], \"Results\": { \"county\": [ { \"geographyType\": \"COUNTY2010\", \"stateFips\": \"37\", \"fips\": \"37063\", \"name\": \"Durham\" } ] } } Original Data Source: Master Building Permit Data Set↩ Wikipedia entry for JSON↩ "],
["grel.html", "2 Hands-on: GREL 2.1 Custom Facets 2.2 GREL to Transform and Normalize Regular Expression Filter Text Facet Cluster Mass Editing via Facets", " 2 Hands-on: GREL The goal of this project is to create custom facets and perform basic transformations, introduce you to GREL – the General Refine Expression Language – and develop practical skills in transforming and normalizing data. You’ve used GREL several times getting to this point in this workbook, but lets look a little deeper. In this example you will open a new data set to practice importing a different type of data, this time comma separated value, or CSV. Last time you imported a tab separated value, or TSV. OpenRefine will important many types of data. Being aware of different data formats, and having the ability to open those data are valuable skills. In fact, one of the most frequent stumbling blocks when using new data tools is the simple problem of importing the data. Practice and learn… 2.1 Custom Facets Download new Data then Create a new OpenRefine Project: We’ll use a subset6 of data from the Raleigh Open Data portal: “Raleigh Police Incident Data 2005plus2014.csv”. Import Data Create Project &gt; Web Addresses (URLs) &gt; https://github.com/libjohn/openrefine/raw/master/data/Raleigh%20Police%20Incident%20Data%202005plus2014.csv Next &gt;&gt; You many want to give your project a pretty title Create Project &gt;&gt; Isolate data: you have incident data without location information Location &gt; Facet &gt; Customized facets &gt; Facet by blank Click true (True = cell is blank ; False = cell has data) How many matching rows have no location data? 10,576 Explanation In the step above, you limited your data set to find all the police incident data where there is no location information. That is, when the cell is blank,there there is no location information. Explanation for the next step: You’ll create a custom facet (by Year) without altering any data. To do this, you’ll use a very simple expression which takes a slice of data based on fixed position, starting in position 6 (counting begins at 0) and ending four character positions later at 10* (6 + 4=10). Given the data, find the year value within the “INC DATETIME” field. DATA: 12/31/2014 11:05:00 PM Position: 0123 6 1 2 1 0 For Example… - To take the year“2014”, use expression: value[6,10]7 - To take the hour, use value[11,13] - To take PM (or AM), use value[20,22] Create a Custom Facet to Sort by Year INC DATETIME &gt; Facet &gt; Custom text facet … Expression = value[6,10] &gt; OK Sort the facet by Count Which year has the most missing data? 2005 How many rows match that year? 10,007 rows with missing location data Click “Remove All” in the Facet/Filter sidebar Keep only the data with location values, i.e. delete all rows that have no location data… Location &gt; Facet &gt; Customized facets &gt; Facet by blank Limit to “true” All &gt; Edit rows &gt; Remove all matching rows Close (“X out”) the facets 2.2 GREL to Transform and Normalize The General Refine Expression Language (GREL) is a powerful and extensible language to manipulate data. In these next steps we will learn GREL by using practical steps to improve the structure of the data. Split the LOCATION Column into two columns (Latitude and Longitude) LOCATION &gt; Edit column &gt; Split into several columns… &gt; OK (i.e. Accept the defaults) Rename Columns Location 1 &gt; Edit column &gt; Rename this column &gt; Latitude Location 2 &gt; Edit column &gt; Rename this column &gt; Longitude Remove parenthesis and trim whitespace Latitude &gt; Edit cells &gt; Transform … Expression = value.replace(&quot;(&quot;,&quot;&quot;) &gt; OK Latitude &gt; Edit cells &gt; Common transformations &gt; Trim leading and trailing whitespace Longitude &gt; Edit cells &gt; Transform … Expression = value.replace(&quot;)&quot;,&quot;&quot;) &gt; OK Longitude &gt; Edit cells &gt; Common transformations &gt; Trim leading and trailing whitespace Regular Expression Regular Expressions are very powerful and flexible codes used for matching patterns. Often there is more than one way to compose a regex pattern-match. Importantly for OpenRefine, much of Refine’s extensible and advanced power comes from regular expressions. Essentially the key to advanced level OpenRefine is regular expressions and looping. To learn more about regular expressions see my handout on regex. For now you can refer to these few commands and symbols summed up on this quick-sheet. Create New Column from Existing Column using a regular expression to match a pattern INC DATETIME &gt; Edit column &gt; Add column based on this column … New column name = YEAR Expression = value.match(/.*\\/(\\d\\d\\d\\d).*/)[0] &gt; OK8 Filter Text Create a Text Filter: Explore your data to find how many incident descriptions involve bicycles LCR DESC &gt;Text filter In the filter box, enter the term bicycle How many matching rows of data use the word “bicycle” in the description? 251 Facet Make a Text Facet on the LCR DESC column LCR DESC &gt; Facet &gt; Text facet How many Bicycle categories exist in the facet window? 6 Which facet is most often used “LCR DESC” facet? LARCENY/BICYCLES ($50-$199) - 119 Cluster Look for Cluster variations in the FELONY Column Clustering refers to the operation of finding groups of different values that might be alternative representations of the same thing. For example “Gödel” and “Godel”. This is a handy way to find spelling variations. FELONY &gt; Facet &gt; Text facet FELONY &gt; Edit cells &gt; Cluster and edit … Method = “key collision” ; Key Function = “metaphone3” For each row, check “Merge?” and change the “New Cell Value” to Felony in the first row to Not Felony in the second row click the “Merge Selected &amp; Re-Cluster” button Try other “Methods” and “Keying Functions”. “Merge Selected &amp; Re-Cluster” after each operation Close How many “Not Felony” bicycle larcenies were recorded? There are 234 “Not Felony” items after clustering using both “key collision” and “nearest neighbor” methods of clustering Mass Editing via Facets Mass Edit cells in LCR DESC Facet: LCR DESC &gt; Facet &gt; Text facet Mouseover &amp; Edit “LARCENY/BICYCLE/FELONY/$200- …” delete “/FELONY” Add an “S” to ‘BICYCLE’ &gt; Apply How many rows match the “LARCENY/BICYCLES ($200-$1000)” Category There are 115 observatins (or rows) matching “LARCENY/BICYCLES ($200-$1,000)” category Export as an Excel File Export &gt; Excel Original Data Source: Raleigh Open Data↩ You may notice what seems to be either a math or logic error in how this second value is “counted.” The simple explanation is the first number counts from zero. Add to that number the string length counting from 1 to get the second value.↩ Here’s another GREL example that captures the same data: value.match(/(\\d\\d)\\/\\d{2}\\/(\\d{4})\\s.*\\s([A|P][M])/)[1]↩ "],
["hands-on-reshape.html", "3 Hands-on: reshape 3.1 Ingest Excel data 3.2 Facets 3.3 Text Filter", " 3 Hands-on: reshape Reshaping Your Data For this project you will take data in one format and reshape into a more optimal format for analysis. We’ll assume the analysis will be done in another tool. OpenRefine can export data in multiple formats after the data has been wrangled into the proper structure. In this lab we continue exploring how OpenRefine can import various data formats, this time Excel. Goals 1. Import Excel worksheets 2. Faceting &amp; Filtering for select data cleaning 3. Transforming: Adding columns and using fill-down to fill in data The changes outline above are minor changes to the shape of the data. The content of the data remains unchanged. Basically you will transform the data to remove confusion in the first column. You can see how the data will change by looking at the before and after examples, below. In the before example (table 3.1) there are different variable concepts in the first column: team and player. In the after example (table 3.2) we move each concept (variable) into its own column. I encourage you to download the Excel spreadsheet and look through the raw data. 9 Doing so will help you see how the data transformation progresses. The video demonstrates how the data will be transformed in this exercise. Before Table 3.1: Unprocessed: A selective 10 rows of the 2013-2014 Salary.xls data Cartier Martin 876332 c$754,250, r1/7, s2/1-2/18, s2/21 Mike Scott 778872 minimum Mike Muscala 57668 signed 2/27, released 3/23 James Nunnally 57668 signed 1/11, released 2/1 Dexter Pittman 53888 c $52,017, signed 2/22, rel 2/27 NA NA NA —- NA NA NA NA NA Boston Celtics NA NA Kris Humphries 12000000 NA After Table 3.2: Wrangled: same 10 rows of the 2013-2014 Salary.xls data Player Team Salary Notes Cartier Martin Atlanta Hawks 876332 c$754,250, r1/7, s2/1-2/18, s2/21 Mike Scott Atlanta Hawks 778872 minimum Mike Muscala Atlanta Hawks 57668 signed 2/27, released 3/23 James Nunnally Atlanta Hawks 57668 signed 1/11, released 2/1 Dexter Pittman Atlanta Hawks 53888 c $52,017, signed 2/22, rel 2/27 Kris Humphries Boston Celtics 12000000 NA Rajon Rondo Boston Celtics 12000000 NA Gerald Wallace Boston Celtics 10105855 NA Jeff Green Boston Celtics 8700000 NA Brandon Bass Boston Celtics 6450000 NA 3.1 Ingest Excel data Import Data Create Project &gt; Web Addresses (URLs) &gt; https://github.com/libjohn/openrefine/raw/master/data/salary.xlsx Next &gt;&gt; You many want to give your project a pretty title Parse data as Worksheets to Import: Check “2013-2014 666 rows” UnCheck “2014-2015 599 rows” UnCheck “Store blank rows” Notice lines 20 &amp; 22 disappear UnCheck “Parse Next” 1 lines as column headers Notice the “Atlanta Hawks” are no longer the column header for the first column Project name = salary data &gt; Create Project Rename Columns: “Player”, “Salary”, “Notes” 10 Show as: rows to ‘25’ (notice row 21) 3.2 Facets Remove all rows where ‘—-’ exist in the Player column Player &gt; Facet &gt; Text Facet** &gt; Sort by: count &gt; click: ‘—-’ : You should now have 29 matching rows that begin ‘—-’ All &gt; Edit rows &gt; Remove all matching rows Click: Remove All in the Facet/Filter sidebar Notice: in the next step, team names precede each team roster and are followed by two blank cells in the same row. Scroll through the screens (Click “next &gt;”) a few times; return to the first screen Make a column for team name and fill it. Isolate team-name rows using a facet on the blank cells in the Salary column Salary &gt; Facet &gt; Customized facets &gt; Facet by blank Why do you think this doesn’t work? Those cells are actually filled with whitespace – invisible to the naked eye but legitimate characters for a computer: a space (\\s). They’re not actually blank and only appear blank. So, regular expressions to the rescue! Close the facet Salary &gt; Text filter &gt; check “regular expression” &gt; ^\\s \\s means “a space”; ^ means “must begin the line” Mouseover the the “Cleveland Cavaliers” Salary cell: edit &gt; highlight all the text EXCEPT the first space: “Tot $66,611,520” &gt; &lt;&lt;cut to clipboard&gt;&gt; &gt; Apply BE SURE to leave a blank space where the Salary data was Edit the individual Notes cell for the “Cleveland Cavaliers” cell: edit &gt; &lt;&lt;paste from clipboard&gt;&gt; “Tot $66,611,520” &gt; Apply This time you do not need a leading blank space 3.3 Text Filter Add the team name as a new column for each player then remove team name from the Player Column Player &gt; Edit column &gt; Add column based on this column … &gt; New column name = Team &gt; OK Remove All facets Team &gt; Edit cells &gt; Fill down Salary &gt; Text filter &gt; check “regular expression” &gt; ^\\s All &gt; Edit rows &gt; Remove all matching rows Close (or “X out”) the Salary text filter The data, “Salary.xslx”, are NBA salary data.↩ Column Header &gt; Edit Column &gt; Rename this column ↩ "],
["hands-on-dates.html", "4 Hands-on: dates 4.1 Dates 4.2 Logic", " 4 Hands-on: dates Dates are weird!11 Or, more accurately, Time is philosophically fascinating and sometimes difficult to represent. This is true for your brain and it’s especially true for your computer. Keep in mind that converting dates (i.e. using the toDate() function) format sometimes results in errors because time and date formats are weird. Often, in OpenRefine, it’s easiest to operate on strings and convert to dates (or to numbers) as needed. For example, sometimes it’s easier to use a slice() of a string and then convert to date, or to number if you really need to do so. However, in OpenRefine, the date format is necessary for date faceting and for finding the difference between two dates (e.g. using the diff() function, or for getting a datePart() for retrieving an hour, or second). This project will give you practice manipulating dates 4.1 Dates Open the existing Refine Project Raleigh Building Permits, (from Project 1) Make a copy of the issue_date column issue_date &gt; Edit column &gt; Add column based on this column… new column name = date2 &gt; OK Create a customized facet on AM/PM issue_date &gt; Facet &gt; Custom text facet … Expression = value.slice(20,22) Create a customized facet on the hour issue_date &gt; Facet &gt; Custom text facet… Expression = value.slice(10,13) Convert to Date date2 &gt; Edit cells &gt; Common transforms &gt; To Date The status message indicates 19598 rows were transformed, but there are 21982 rows of data, what went wrong? Select the “PM” custom text facet and the “12” custom text facet Do you see that none of the dates converted when the time included 12PM? For whatever reason, the date converter doesn’t like timestamps that contain 12PM as a designation So let’s convert those dates from 12PM to 00PM (Why? because it fixes the problem) Convert 12PM to 00PM date2 Edit cells &gt; transform Expression = value.replace(&quot; 12:&quot;,&quot; 00:&quot;) Now convert to date date2 &gt; Edit cells &gt; Common transforms &gt; To Date That converts 2384 cells Now, Remove All facets Now make a date facet date2 &gt; Facet &gt; Timeline facet 4.2 Logic This time we’ll put together everything we’ve learned (how to use OpenRefine, regular expressions, GREL) and add in some logic control statements (i.e. an IF statment.) Our goal is to create the same timeline facet but with fewer, more complex OpenRefine steps. You will see in this example that while OpenRefine is a powerful data transformation tool which can easily support casual attention to syntax, file handling, and looping; OpenRefine is also a powerful and extensible tool which supports scripting and begins to look like real programming. In other words, it’s an extensible data transformation tool. Goal: Make the same data transformations as in the previous slide’s steps 2-7, but this time you’ll do it in one step. Think about how GREL allows you to take shortcuts. issue_date &gt; Edit Column &gt; Add column based on this column… New Column Name = date3 Expression = if(value.slice(20,22) == &quot;PM&quot;, value.replace(/(.*\\s)12(:\\d\\d:.*)/,&quot;$100$2&quot;), value).toDate() Now make a date facet date3 &gt; Facet &gt; Timeline facet Dates are Difficult by Mike James (www.i-programmer.info)↩ "],
["hands-on-reconciliation.html", "5 Hands-on: Reconciliation 5.1 Reconciliation 5.2 Reconciliation Resources", " 5 Hands-on: Reconciliation OpenRefine’s Reconciliation service is used to semi-automate the process of matching data in OpenRefine fields with more authoritative data in external sources. This reconciliation function is called semi-automated because the end-user is given the opportunity to interactively approve or select which data are modified by choosing from a pick-list of results. This process can be used to improve and standardize individual data fields or columns of data inside of OpenRefine. Or it can be used to extend the data in OpenRefine. For example: Match each name in a list of authors against an external authoritative list of authors. Augment the authoritative entry of each author’s name; Add an example book title for each author. 5.1 Reconciliation Goal: Import new author data into a new project, Use the WikiData and VIAF reconciliation services to gather authoritative versions of African American author names and an example of each author’s work, plus their placed of birth and death. Make a New Project, Import Author Data Create Project &gt; Web Addresses (URLs) &gt; https://raw.githubusercontent.com/libjohn/openrefine/master/data/AA-authors-you-should-read.csv Next &gt;&gt; You many want to give your project a pretty title Create Project &gt;&gt; author &gt; Reconcile &gt; Start reconciling… Change the Show: to 25 so you can see all 11 records. First time / One time … Add Standard Service… In the Enter the service’s URL: textbox, enter: http://refine.codefork.com/reconcile/viaf12 Name = “Reconciled Authors” click VIAF Under Reconcile each cell to an entity of one of these types:, choose Work Click, Start Reconciling authors &gt; Reconcile &gt; Actions &gt; Match each cell to its best candidate authors &gt; Edit column &gt; Add column based on this column… New column name = major works Expression = cell.recon.candidates[0].name 13 OK The rest of the time… author &gt; Reconcile &gt; Start reconciling… Under Services, click Wikidata Reconciliation for OpenRefine (en) Under Reconcile each cell to an entity of one of these types:, choose, human Click, Start Reconciling In the left-hand sidebar, Remove All facets By clicking the approriate single checkbox in each cell of the authors column, manually slect the most appropriate author for our topic. (Our topic is African American Authors everyone should read). Not every cell has an author for which you must make a selection. Cells 2, 10 need your intervention. In Cell 2, James Baldwin, select the first option which a match of “(100)” In cell 10, Click on the first name, then the second name. Do you see an African-American writer? Choose him by clicking the corresponding single check-mark Add more metadata from Wiki Data (only works for Wikidata as of this writing) authors &gt; Edit column &gt; Add columns from reconciled values… Under Suggested Properties, click place of birth and place of death OK Copy the author and dates information from the ‘Richard Wright’ cell under the “major works” column; Edit the Richard Write cell under the “authors” column ; paste in the more complete information: Wright, Richard, 1908-1960 Add authoritative author data from VIAF author &gt; Reconcile &gt; Start reconciling… Under Reconcile each cell to an entity of one of these types:, choose Person Click, Start Reconciling authors &gt; Reconcile &gt; Actions &gt; Match each cell to its best candidate By useing the Choose new match option, fix row 2. Transform the “major works” column by splitting the column at the pipe: `|’ Can Export as CSV (Excel, etc.) with Reconciled info. 5.2 Reconciliation Resources YouTube: Reconcilliation in OpenRefine: Part 1 by Owen Stephens YouTube: Reconcilliation in OpenRefine part 2 Reconciliation Data Sources For low use needs: VIAF / ORCID / Open Library For more advanced needs: conciliator OpenRefine documentation on Reconciliation OpenRefine technical documentation on reconciliation API Transform Recon Candidates to cell data: e.g. cell.recon.candidates[0].id http://refine.codefork.com/↩ http://liwong.blogspot.com/2017/07/tutorial-on-objects-and-cellrecon-object.html↩ "],
["hands-on-web-scraping.html", "6 Hands-on: Web Scraping 6.1 API 6.2 Parse 6.3 Keys 6.4 Exercise 2", " 6 Hands-on: Web Scraping Goal: We want to gather the FIPS code for some data by matching a county name to a government server which maintains a server that enables FIPS lookups. The government server returns data in a JSON format. After gathering the data we’ll parse the JSON format and isolate the particular data from the data wrapper. Import Data Create Project &gt; Web Addresses (URLs) &gt; https://raw.githubusercontent.com/libjohn/openrefine/master/data/subset-Raleigh-Building-Permits-for-API-JSON-parsing.csv Next &gt;&gt; You many want to give your project a pretty title Create Project &gt;&gt; 6.1 API Now let’s fetch the data from a Web API made available via the National Broadband Map (NBM | NBM Developer). This API returns a FIPS code, given a county name (or in this case, even a partial county name.) We’ll use the API documentation for Geography by Name API14. In this case, simply use the County value as the search string wrapped in the API query protocol. Fetch JSON data from the National Broadband Map. county &gt; Edit column &gt; Add column by fetching URLs… New column name = JSON data Throttle delay = 2000 Expression = 'https://www.broadbandmap.gov/broadbandmap/census/county/'+value+'?format=json' OK 6.2 Parse Now parse the value of the JSON data “fips” element; call the “fips” key when traversing the “county” objects from the Results set. JSON data &gt; Edit column &gt; Add column based on this column … New column name = FIPS Code expression = value.parseJson().Results.county[0].fips 15 OK JSON Data Example JSON 16 is JavaScript Object Notation a data wrapper. The API, in this case, returns the data in a JSON format. { \"status\": \"OK\", \"responseTime\": 14, \"message\": [ ], \"Results\": { \"county\": [ { \"geographyType\": \"COUNTY2010\", \"stateFips\": \"37\", \"fips\": \"37063\", \"name\": \"Durham\" } ] } } 6.3 Keys Web API keys are typically issued by the API service to help identify the origin of the API request. Contrary to the above example, most API services require keys. In this next example you’ll practice getting and using a key. In this case the key is free. They are not always free. Go to the OMDB API key request page. Enter your email and choose the free key option. Check your email for your key. You’ll use this key appended to your search query. The documentation for this API can found at their Parameters section. It’s also helpful to have a look at the Examples section. 6.4 Exercise 2 You’ll need your API key from the preceding steps. Create a new project in OpenRefine Click the Clipboard option, under Get data from and paste in the following: The Warriors Rocky Bambi Give your project a nice name (e.g. “Movies”) and Create Project &gt;&gt; Fetch JSON data from the OMDB API Column 1 &gt; Edit column &gt; Add column by fetching URLs… New column name = JSON data Throttle delay = 2000 Expression = 'http://www.omdbapi.com/?t=' + escape(value, &quot;url&quot;) + '&amp;' + 'apikey=Yogi-and-BOO-BOO-BOY' Be sure to substitute your actual api key (see above) for Yogi-and-BOO-BOO-BOY OK Parse JSON data &gt; Edit column &gt; Add column based on this column … New column name = Year expression = value.parseJson().Year OK JSON data &gt; Edit column &gt; Add column based on this column … New column name = Poster expression = value.parseJson().Poster OK The documentation informs us that the format of the URL we want to construct is as follows: http://www.broadbandmap.gov/broadbandmap/census/county/durh?format=json↩ Note the square-bracket ([0]) notation in the ParseJson() function denotes and identifies the first array element. It’s the first element because in OpenRefine counting begins with zero (e.g. 0,1,2,3,4,5). The county array in the example below consists of only 1 value element (consisting of four, named key/value pairs; of which fips is one key). Since the JSON notation indicates county is an array, in this case of quantity 1, we identify that first element of the array by the number ‘0’. See the JSON example.↩ Wikipedia entry for JSON↩ "],
["hands-on-html-parsing.html", "7 Hands-on: HTML Parsing 7.1 Fetch 7.2 Parse 7.3 Inspect your work…", " 7 Hands-on: HTML Parsing Goal: Learn how to use OpenRefine’s HTML parsing capabilities by fetching some David Price press releases and then parsing the content. Import Data Create Project &gt; Web Addresses (URLs) &gt; https://raw.githubusercontent.com/libjohn/openrefine/master/data/price-crawl-and-HTML-parse.csv Next &gt;&gt; You many want to give your project a pretty title Create Project &gt;&gt; 7.1 Fetch Now let’s fetch the data by crawling a few links to Congressman Price’s press releases. This will return large amounts of raw HTML that can be hard to read. So, after fetching, we’ll parse the result. Fetch HTML prlink-href &gt; Edit column &gt; Add column by fetching URLs… New column name = raw HTML Throttle delay = 2000 Expression = value OK 7.2 Parse Now parse the HTML data. raw HTML &gt; Edit column &gt; Add column based on this column … New column name = HTML title expression = value.parseHtml().select(&quot;title&quot;)[0].htmlText() 17 OK raw HTML &gt; Edit column &gt; Add column based on this column … New column name = body title expression = value.parseHtml().select(&quot;h1#page-title.title&quot;)[0].htmlText() OK raw HTML &gt; Edit column &gt; Add column based on this column … New column name = date2 expression = value.parseHtml().select(&quot;div.pane-content&quot;)[0].htmlText() OK raw HTML &gt; Edit column &gt; Add column based on this column … New column name = dateline expression = value.parseHtml().select(&quot;div.field-item.even p strong&quot;)[0].htmlText() OK raw HTML &gt; Edit column &gt; Add column based on this column … New column name = links expression = forEach( value.parseHtml().select(&quot;div#block-system-main&quot;)[0].select(&quot;a&quot;), e, e.htmlAttr(&quot;href&quot;) ).join(&quot;|&quot;) OK raw HTML &gt; Edit column &gt; Add column based on this column … New column name = link text expression = forEach( value.parseHtml().select(&quot;div#block-system-main&quot;)[0].select(&quot;a&quot;), e, e.htmlText() ).join(&quot;|&quot;) OK 7.3 Inspect your work… raw HTML &gt; View &gt; Collapse this column Click the records link in the “Show as: rows records” section, above the column headers links &gt; Edit cells &gt; Split multi-valued cells… for the by separator option, in the Separator textbox enter a pipe: | repeate this step for the link text column Look around. Scroll left to right and wee what you’ve parsed. Note the square-bracket ([0]) notation in the ParseHtml() function denotes and identifies the first array element. It’s the first element because in OpenRefine counting begins with zero (e.g. 0,1,2,3,4,5).↩ "]
]
